# 课程目录 

第1讲-课程介绍
第2讲-课程环境搭建：CentOS 6.4集群搭建
第3讲-课程环境搭建：hadoop-2.5.0-cdh5.3.6集群搭建
第4讲-课程环境搭建：hive-0.13.1-cdh5.3.6安装
第5讲-课程环境搭建：zookeeper-3.4.5-cdh5.3.6集群搭建
第6讲-课程环境搭建：kafka_2.9.2-0.8.1集群搭建
第7讲-课程环境搭建：flume-ng-1.5.0-cdh5.3.6安装
第8讲-课程环境搭建：离线日志采集流程介绍
第9讲-课程环境搭建：实时数据采集流程介绍
第10讲-课程环境搭建：Spark 1.5.1客户端安装以及基于YARN的提交模式
第11讲-用户访问session分析：模块介绍
第12讲-用户访问session分析：基础数据结构以及大数据平台架构介绍
第13讲-用户访问session分析：需求分析
第14讲-用户访问session分析：技术方案设计
第15讲-用户访问session分析：数据表设计
第16讲-用户访问session分析：Eclipse工程搭建以及工具类说明
第17讲-用户访问session分析：开发配置管理组件
第18讲-用户访问session分析：JDBC原理介绍以及增删改查示范
第19讲-用户访问session分析：数据库连接池原理
第20讲-用户访问session分析：单例设计模式
第21讲-用户访问session分析：内部类以及匿名内部类
第22讲-用户访问session分析：开发JDBC辅助组件（上）
第23讲-用户访问session分析：开发JDBC辅助组件（下）
第24讲-用户访问session分析：JavaBean概念讲解
第25讲-用户访问session分析：DAO模式讲解以及TaskDAO开发
第26讲-用户访问session分析：工厂模式讲解以及DAOFactory开发
第27讲-用户访问session分析：JSON数据格式讲解以及fastjson介绍
第28讲-用户访问session分析：Spark上下文构建以及模拟数据生成
第29讲-用户访问session分析：按session粒度进行数据聚合
第30讲-用户访问session分析：按筛选参数对session粒度聚合数据进行过滤
第31讲-用户访问session分析：session聚合统计之自定义Accumulator
第32讲-用户访问session分析：session聚合统计之重构实现思路与重构session聚合
第33讲-用户访问session分析：session聚合统计之重构过滤进行统计
第34讲-用户访问session分析：session聚合统计之计算统计结果并写入MySQL
第35讲-用户访问session分析：session聚合统计之本地测试
第36讲-用户访问session分析：session聚合统计之使用Scala实现自定义Accumulator
第37讲-用户访问session分析：session随机抽取之实现思路分析
第38讲-用户访问session分析：session随机抽取之计算每天每小时session数量
第39讲-用户访问session分析：session随机抽取之按时间比例随机抽取算法实现
第40讲-用户访问session分析：session随机抽取之根据随机索引进行抽取
第41讲-用户访问session分析：session随机抽取之获取抽取session的明细数据
第42讲-用户访问session分析：session随机抽取之本地测试
第43讲-用户访问session分析：top10热门品类之需求回顾以及实现思路分析
第44讲-用户访问session分析：top10热门品类之获取session访问过的所有品类
第45讲-用户访问session分析：top10热门品类之计算各品类点击、下单和支付的次数
第46讲-用户访问session分析：top10热门品类之join品类与点击下单支付次数
第47讲-用户访问session分析：top10热门品类之自定义二次排序key
第48讲-用户访问session分析：top10热门品类之进行二次排序
第49讲-用户访问session分析：top10热门品类之获取top10品类并写入MySQL
第50讲-用户访问session分析：top10热门品类之本地测试
第51讲-用户访问session分析：top10热门品类之使用Scala实现二次排序
第52讲-用户访问session分析：top10活跃session之开发准备以及top10品类RDD生成
第53讲-用户访问session分析：top10活跃session之计算top10品类被各sessoin点击的次数
第54讲-用户访问session分析：top10活跃session之分组取TopN算法获取top10活跃session
第55讲-用户访问session分析：top10活跃session之本地测试以及阶段总结
第56讲-用户访问session分析：性能调优之在实际项目中分配更多资源
第57讲-用户访问session分析：性能调优之在实际项目中调节并行度
第58讲-用户访问session分析：性能调优之在实际项目中重构RDD架构以及RDD持久化
第59讲-用户访问session分析：性能调优之在实际项目中广播大变量
第60讲-用户访问session分析：性能调优之在实际项目中使用Kryo序列化
第61讲-用户访问session分析：性能调优之在实际项目中使用fastutil优化数据格式
第62讲-用户访问session分析：性能调优之在实际项目中调节数据本地化等待时长
第63讲-用户访问session分析：JVM调优之原理概述以及降低cache操作的内存占比
第64讲-用户访问session分析：JVM调优之调节executor堆外内存与连接等待时长
第65讲-用户访问session分析：Shuffle调优之原理概述
第66讲-用户访问session分析：Shuffle调优之合并map端输出文件
第67讲-用户访问session分析：Shuffle调优之调节map端内存缓冲与reduce端内存占比
第68讲-用户访问session分析：Shuffle调优之HashShuffleManager与SortShuffleManager
第69讲-用户访问session分析：算子调优之MapPartitions提升Map类操作性能
第70讲-用户访问session分析：算子调优之filter过后使用coalesce减少分区数量
第71讲-用户访问session分析：算子调优之使用foreachPartition优化写数据库性能
第72讲-用户访问session分析：算子调优之使用repartition解决Spark SQL低并行度的性能问题
第73讲-用户访问session分析：算子调优之reduceByKey本地聚合介绍
第74讲-用户访问session分析：troubleshooting之控制shuffle reduce端缓冲大小以避免OOM
第75讲-用户访问session分析：troubleshooting之解决JVM GC导致的shuffle文件拉取失败
第76讲-用户访问session分析：
第77讲-用户访问session分析：troubleshooting之解决各种序列化导致的报错
第78讲-用户访问session分析：troubleshooting之解决算子函数返回NULL导致的问题
第79讲-用户访问session分析：troubleshooting之解决yarn-client模式导致的网卡流量激增问题
第80讲-用户访问session分析：troubleshooting之解决yarn-cluster模式的JVM栈内存溢出问题
第81讲-用户访问session分析：troubleshooting之错误的持久化方式以及checkpoint的使用
第82讲-用户访问session分析：数据倾斜解决方案之原理以及现象分析
第83讲-用户访问session分析：数据倾斜解决方案之聚合源数据以及过滤导致倾斜的key
第84讲-用户访问session分析：数据倾斜解决方案之提高shuffle操作reduce并行度
第85讲-用户访问session分析：数据倾斜解决方案之使用随机key实现双重聚合
第86讲-用户访问session分析：数据倾斜解决方案之将reduce join转换为map join
第87讲-用户访问session分析：数据倾斜解决方案之sample采样倾斜key单独进行join
第88讲-用户访问session分析：数据倾斜解决方案之使用随机数以及扩容表进行join
第89讲-页面单跳转化率：模块介绍
第90讲-页面单跳转化率：需求分析、技术方案设计、数据表设计
第91讲-页面单跳转化率：编写基础代码
第92讲-页面单跳转化率：页面切片生成以及页面流匹配算法实现
第93讲-页面单跳转化率：计算页面流起始页面的pv
第94讲-页面单跳转化率：计算页面切片的转化率
第95讲-页面单跳转化率：将页面切片转化率写入MySQL
第96讲-页面单跳转化率：本地测试
第97讲-页面单跳转化率：生产环境测试
第98讲-用户访问session分析：生产环境测试
第99讲-各区域热门商品统计：模块介绍
第100讲-各区域热门商品统计：需求分析、技术方案设计以及数据设计
第101讲-各区域热门商品统计：查询用户指定日期范围内的点击行为数据
第102讲-各区域热门商品统计：异构数据源之从MySQL中查询城市数据
第103讲-各区域热门商品统计：关联城市信息以及RDD转换为DataFrame后注册临时表
第104讲-各区域热门商品统计：开发自定义UDAF聚合函数之group_concat_distinct()
第105讲-各区域热门商品统计：查询各区域各商品的点击次数并拼接城市列表
第106讲-各区域热门商品统计：
第106讲-各区域热门商品统计：使用开窗函数统计各区域的top3热门商品
第107讲-各区域热门商品统计：使用内置case when函数给各个区域打上级别标记
第108讲-各区域热门商品统计：将结果数据写入MySQL中
第109讲-各区域热门商品统计：Spark SQL数据倾斜解决方案
第110讲-各区域热门商品统计：生产环境测试
第111讲-广告点击流量实时统计：需求分析、技术方案设计以及数据设计
第112讲-广告点击流量实时统计：
第113讲-广告点击流量实时统计：使用高性能方式将实时计算结果写入MySQL中
第114讲-广告点击流量实时统计：过滤出每个batch中的黑名单用户以生成动态黑名单
第115讲-广告点击流量实时统计：基于动态黑名单进行点击行为过滤
第116讲-广告点击流量实时统计：计算每天各省各城市各广告的点击量
第117讲-广告点击流量实时统计：计算每天各省的top3热门广告
第118讲-广告点击流量实时统计：计算每天各广告最近1小时滑动窗口内的点击趋势
第119讲-广告点击流量实时统计：实现实时计算程序的HA高可用性
第120讲-广告点击流量实时统计：对实时计算程序进行性能调优（正确）
第121讲-广告点击流量实时统计：生产环境测试
第122讲-课程总结：都学到了什么？
第123讲-（赠送）Spark 2.0-新特性介绍
第124讲-（赠送）Spark 2.0-新特性介绍-易用性：标准化SQL支持以及更合理的API
第125讲-（赠送）Spark 2.0-新特性介绍-高性能：让Spark作为编译器来运行
第126讲-（赠送）Spark 2.0-新特性介绍-智能化：Structured Streaming介绍
第127讲-（赠送）Spark 2.0-新特性介绍-Spark 1.x的Volcano Iterator Model技术缺陷分析
第128讲-（赠送）Spark 2.0-新特性介绍-
第129讲-（赠送）Spark 2.0-Spark 2.x与1.x对比以及分析、学习建议以及使用建议
第130讲-（赠送）Spark 2.0-课程环境搭建：虚拟机、CentOS、Hadoop、Spark等
第131讲-（赠送）Spark 2.0-开发环境搭建：Eclipse+Maven+Scala+Spark
第132讲-基于Spark 2.0的用户活跃度分析：模块介绍以及交互式用户行为分析系统的解释
第133讲-基于Spark 2.0的用户活跃度分析：统计指定时间内访问次数最多的10个用户
第134讲-基于Spark 2.0的用户活跃度分析：统计指定时间内购买金额最多的10个用户
第135讲-基于Spark 2.0的用户活跃度分析：统计最近一个周期相比上一个周期访问次数增长最多的10个用户
第136讲-基于Spark 2.0的用户活跃度分析：统计最近一个周期相比上一个周期购买金额增长最多的10个用户
第137讲-基于Spark 2.0的用户活跃度分析：统计指定注册时间范围内头7天访问次数最高的10个用户
第138讲-基于Spark 2.0的用户活跃度分析：统计指定注册时间范围内头7天购买金额最高的10个用户



# 第1讲-课程介绍


## 1、课程介绍
本套课程主要讲解一个真实、复杂的大型企业级大数据项目。是Spark的大型项目实战课程。通过本套课程的学习，学员可以积累大量的Spark项目经验。在学员本身Spark技术就很好的情况下，学习完本套课程之后，可以达到有2年Spark大数据开发经验的水平。

本课程可以正式让学员迈入Spark高级开发工程师的行列！在跳槽或者面试的时候，精湛的Spark技术以及复杂的Spark大数据项目的经验，足以让你应付国内任何公司的面试（包括BAT等顶级互联网公司的面试难度），从而让学员通过学习掌握自己的人生！

特别声明的是，本套课程的学习，是需要Java、Hadoop和Spark基础的。如果没有相关基础的同学，需要自己先自学相关的基础知识。在课程中，对于一些Java的高级知识点，也会加以讲解，但是学员还是必须有Java编程的基础。

如果学员没有Spark基础的话，推荐学习北风网的《Spark从入门到精通（Scala编程、案例实战、高级特性、Spark内核源码剖析、Hadoop高端）》课程。


## 2、项目介绍
本项目主要用于互联网电商企业中，使用Spark技术开发的大数据统计分析平台，对电商网站的各种用户行为（访问行为、购物行为、广告点击行为等）进行复杂的分析。用统计分析出来的数据，辅助公司中的PM（产品经理）、数据分析师以及管理人员分析现有产品的情况，并根据用户行为分析结果持续改进产品的设计，以及调整公司的战略和业务。最终达到用大数据技术来帮助提升公司的业绩、营业额以及市场占有率的目标。

项目主要采用目前大数据领域最流行、最热门的技术——Spark，具有普通项目无法比拟的技术前瞻性与尖端性。本项目使用了Spark技术生态栈中最常用的三个技术框架，Spark Core、Spark SQL和Spark Streaming，进行离线计算和实时计算业务模块的开发。实现了包括用户访问session分析、页面单跳转化率统计、热门商品离线统计、广告流量实时统计4个业务模块。
项目中所有的业务功能模块都是直接从实际企业项目中抽取出来的，业务复杂度绝对没有任何缩水，只是为了更好的贴近大数据实战课程的需要，进行了一定程度上的技术整合和业务整合。该项目的真实性、业务复杂性以及实战型，绝对不是市面上现有的仅几个课时的Demo级的大数据项目可以比拟的。

通过合理的将实际业务模块进行技术整合与改造，该项目完全涵盖了Spark Core、Spark SQL和Spark Streaming这三个技术框架中，几乎所有的功能点、知识点以及性能优化点，仅一个项目，即可全面掌握Spark技术在实际项目中如何实现各种类型的业务需求！在项目中，重点讲解了实际企业项目中积累下来的宝贵的性能调优、troubleshooting以及数据倾斜等知识和技术，几乎所有知识和技术都是全网唯一，是任何其他视频课程以及书本中都没有包含的珍贵经验积累！同时以企业级大数据项目开发流程贯穿每个业务模块的讲解，涵盖了项目开发全流程，包括需求分析、方案设计、数据设计、编码实现、测试以及性能调优等环节，全面还原真实大数据项目的开发流程。该项目的整体商业价值绝对在百万元以上！


## 3、项目介绍
本项目主要用于互联网电商企业中，使用Spark技术开发的大数据统计分析平台，对电商网站的各种用户行为（访问行为、购物行为、广告点击行为等）进行复杂的分析。用统计分析出来的数据，辅助公司中的PM（产品经理）、数据分析师以及管理人员分析现有产品的情况，并根据用户行为分析结果持续改进产品的设计，以及调整公司的战略和业务。最终达到用大数据技术来帮助提升公司的业绩、营业额以及市场占有率的目标。

项目主要采用目前大数据领域最流行、最热门的技术——Spark，具有普通项目无法比拟的技术前瞻性与尖端性。本项目使用了Spark技术生态栈中最常用的三个技术框架，Spark Core、Spark SQL和Spark Streaming，进行离线计算和实时计算业务模块的开发。实现了包括用户访问session分析、页面单跳转化率统计、热门商品离线统计、广告流量实时统计4个业务模块。
项目中所有的业务功能模块都是直接从实际企业项目中抽取出来的，业务复杂度绝对没有任何缩水，只是为了更好的贴近大数据实战课程的需要，进行了一定程度上的技术整合和业务整合。该项目的真实性、业务复杂性以及实战型，绝对不是市面上现有的仅几个课时的Demo级的大数据项目可以比拟的。

通过合理的将实际业务模块进行技术整合与改造，该项目完全涵盖了Spark Core、Spark SQL和Spark Streaming这三个技术框架中，几乎所有的功能点、知识点以及性能优化点，仅一个项目，即可全面掌握Spark技术在实际项目中如何实现各种类型的业务需求！在项目中，重点讲解了实际企业项目中积累下来的宝贵的性能调优、troubleshooting以及数据倾斜等知识和技术，几乎所有知识和技术都是全网唯一，是任何其他视频课程以及书本中都没有包含的珍贵经验积累！同时以企业级大数据项目开发流程贯穿每个业务模块的讲解，涵盖了项目开发全流程，包括需求分析、方案设计、数据设计、编码实现、测试以及性能调优等环节，全面还原真实大数据项目的开发流程。该项目的整体商业价值绝对在百万元以上！


## 4、课程特色
1、市面上目前完全没有任何高端的大数据项目实战类课程，更没有Spark大数据项目实战类课程，本课程是全网唯一的企业级大型Spark大数据实战项目课程！

2、项目中全面覆盖了Spark Core、Spark SQL和Spark Streaming这三个技术框架几乎全部的初级和高级的技术点和知识点。真正让学员学以致用，通过一套课程，即掌握如何将Spark所有的技术点和知识点应用在真实的项目中，来实现业务需求！

3、项目中的4个功能模块，全部是实际企业项目中提取出来的，并进行技术整合和改良过的功能模块。全部是企业级的复杂和真实的需求，业务模块非常之复杂，绝对不是市面上的Demo级别的大数据项目能够想比拟的。学习过后，真正帮助学员增加实际企业级项目的实战经验！

4、项目中通过实际的功能模块和业务场景，以及讲师曾经开发过的处理十亿、甚至百亿以上数据级别的Spark作业的经验积累，贯穿讲解了大量的高级复杂的性能调优技术和知识、troubleshooting解决线上报错和故障的经验、高端的全方位数据倾斜处理和解决方案。真正帮助学员掌握高精尖的Spark技术！

5、项目中采用完全还原企业大数据项目开发场景的方式来讲解，每一个业务模块的讲解都包括了需求分析、方案设计、数据设计、编码实现、功能测试、性能调优等环节，真实还原企业级大数据项目开发场景。让学员掌握真实大数据项目的开发流程和经验！


## 5、课程价值
1、让学员达到2年左右的Spark大数据开发水平，成为Spark高级开发工程师的行列。

2、课程所有模块都是真实的复杂模块，学完本课程以后，稍加改造，立即可以进行二次开发，作为电商类型企业中的用户行为分析大数据平台。课程所赠所有源代码，价值在百万以上！

3、让学员掌握企业级的、全网唯一、独家的Spark项目的复杂性能调优、线上故障解决经验、数据倾斜全套处理方案。

4、让学员通过一套经过改造和改良的项目实战课程，就可以完全将Spark所有技术点和知识点都应用在项目中，掌握如何灵活应用Spark各项技术来实现各种复杂业务需求。


## 6、模块简介
1、用户访问session分析：该模块主要是对用户访问session进行统计分析，包括session的聚合指标计算、按时间比例随机抽取session、获取每天点击、下单和购买排名前10的品类、并获取top10品类的点击量排名前10的session。该模块可以让产品经理、数据分析师以及企业管理层形象地看到各种条件下的具体用户行为以及统计指标，从而对公司的产品设计以及业务发展战略做出调整。主要使用Spark Core实现。

2、页面单跳转化率统计：该模块主要是计算关键页面之间的单步跳转转化率，涉及到页面切片算法以及页面流匹配算法。该模块可以让产品经理、数据分析师以及企业管理层看到各个关键页面之间的转化率，从而对网页布局，进行更好的优化设计。主要使用Spark Core实现。

3、热门商品离线统计：该模块主要实现每天统计出各个区域的top3热门商品。然后使用Oozie进行离线统计任务的定时调度；使用Zeppeline进行数据可视化的报表展示。该模块可以让企业管理层看到公司售卖的商品的整体情况，从而对公司的商品相关的战略进行调整。主要使用Spark SQL实现。

4、广告流量实时统计：该模块负责实时统计公司的广告流量，包括广告展现流量和广告点击流量。实现动态黑名单机制，以及黑名单过滤；实现滑动窗口内的各城市的广告展现流量和广告点击流量的统计；实现每个区域每个广告的点击流量实时统计；实现每个区域top3点击量的广告的统计。主要使用Spark Streaming实现。


## 7、环境介绍
1、CentOS 6.4
2、CDH 5.3.6
3、Spark 1.5.1
4、ZooKeeper 3.4.5
5、Kafka
6、Flume
7、Java（Scala）
8、Eclipse


## 8、Java与Scala的选择说明

本课程的编码实现采用Java。
1、因为Java语言具有高度的稳定性，语法简洁，更容易理解。
2、最重要的一点是，Java并不只是一门编程语言，而是一个生态体系！使用Java开发复杂的大型Spark工程项目，可以让Spark与Redis、Memcaced、Kafka、Solr、MongoDB、HBase、MySQL等第三方技术进行整合使用，因为Java就是一个生态系统，这些第三方的技术无一例外，全部都会包含了Java的API，可以无缝与Spark项目进行整合使用。
3、Java是目前最主流的语言，绝大多数公司里都有一批Java工程师。使用Java开发Spark工程，在项目进行交接、迁移、维护、新人加入时，只要懂得Java的人，都能快速接手和上手Spark开发和项目。更利于项目的交接与维护。

对于Scala，本课程仅仅会在部分重要技术点的使用，比如自定义Accumulator、二次排序等，用Scala辅助讲解一下如何实现。
1、因为Scala的高级语法复杂，学习曲线非常陡峭，不利于学习，容易造成迷惑。
2、因为Scala仅仅只是一门编程语言，而没有达到技术生态的程度。当Spark要与第三方技术，比如Redis、HBase等配合使用时，就只能混合使用Java。此时就会造成一个项目两种语言混编，可维护性与可扩展性大幅度降低。
3、Scala目前远远没有达到普及的程度，会的人很少，在进行项目交接时，如果是Scala的项目，交接过程会很痛苦，甚至导致项目出现问题。




# 第2讲-课程环境搭建：CentOS 6.4集群搭建



# 第3讲-课程环境搭建：hadoop-2.5.0-cdh5.3.6集群搭建




# 第4讲-课程环境搭建：hive-0.13.1-cdh5.3.6安装



# 第5讲-课程环境搭建：zookeeper-3.4.5-cdh5.3.6集群搭建


# 第6讲-课程环境搭建：kafka_2.9.2-0.8.1集群搭建


# 第7讲-课程环境搭建：flume-ng-1.5.0-cdh5.3.6安装


# 第8讲-课程环境搭建：离线日志采集流程介绍


# 第9讲-课程环境搭建：实时数据采集流程介绍



# 第10讲-课程环境搭建：Spark 1.5.1客户端安装以及基于YARN的提交模式




