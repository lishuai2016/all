
<!-- TOC -->

- [第231讲-Spark运维管理进阶-基于ZooKeeper实现HA高可用性以及自动主备切换](#第231讲-spark运维管理进阶-基于zookeeper实现ha高可用性以及自动主备切换)
- [第232讲-Spark运维管理进阶-实验：基于ZooKeeper实现HA高可用性以及自动主备切换](#第232讲-spark运维管理进阶-实验基于zookeeper实现ha高可用性以及自动主备切换)
- [第233讲-Spark运维管理进阶-基于文件系统实现HA高可用性以及手动主备切换](#第233讲-spark运维管理进阶-基于文件系统实现ha高可用性以及手动主备切换)
- [第234讲-Spark运维管理进阶-实验：基于文件系统实现HA高可用性以及手动主备切换](#第234讲-spark运维管理进阶-实验基于文件系统实现ha高可用性以及手动主备切换)
- [第235讲-Spark运维管理进阶-作业监控-实验：通过Spark Web UI进行作业监控](#第235讲-spark运维管理进阶-作业监控-实验通过spark-web-ui进行作业监控)
- [第236讲-Spark运维管理进阶-作业监控-实验：standalone模式下查看历史作业的Web UI](#第236讲-spark运维管理进阶-作业监控-实验standalone模式下查看历史作业的web-ui)
- [第237讲-Spark运维管理进阶-作业监控-实验：启动HistoryServer查看历史作业的Web UI](#第237讲-spark运维管理进阶-作业监控-实验启动historyserver查看历史作业的web-ui)
- [第238讲-Spark运维管理进阶-作业监控-实验：使用curl+REST API进行作业监控](#第238讲-spark运维管理进阶-作业监控-实验使用curlrest-api进行作业监控)
- [第239讲-Spark运维管理进阶-作业监控-实验：Spark Metrics系统以及自定义Metrics Sink](#第239讲-spark运维管理进阶-作业监控-实验spark-metrics系统以及自定义metrics-sink)
- [第240讲-Spark运维管理进阶-作业资源调度-静态资源分配原理](#第240讲-spark运维管理进阶-作业资源调度-静态资源分配原理)
- [第241讲-Spark运维管理进阶-作业资源调度-动态资源分配原理](#第241讲-spark运维管理进阶-作业资源调度-动态资源分配原理)
- [第242讲-Spark运维管理进阶-作业资源调度-实验：standalone模式下使用动态资源分配](#第242讲-spark运维管理进阶-作业资源调度-实验standalone模式下使用动态资源分配)
- [第243讲-Spark运维管理进阶-作业资源调度-实验：yarn模式下使用动态资源分配](#第243讲-spark运维管理进阶-作业资源调度-实验yarn模式下使用动态资源分配)
- [第244讲-Spark运维管理进阶-作业资源调度-多个job资源调度原理](#第244讲-spark运维管理进阶-作业资源调度-多个job资源调度原理)
- [第245讲-Spark运维管理进阶-作业资源调度-Fair Scheduler使用详解](#第245讲-spark运维管理进阶-作业资源调度-fair-scheduler使用详解)

<!-- /TOC -->

# 第231讲-Spark运维管理进阶-基于ZooKeeper实现HA高可用性以及自动主备切换

默认情况下，standalone cluster manager对于worker节点的失败是具有容错性的（迄今为止，Spark自身而言对于丢失部分计算工作
是有容错性的，它会将丢失的计算工作迁移到其他worker节点上执行）。然而，调度器是依托于master进程来做出调度决策的，这就会
造成单点故障：如果master挂掉了，就没法提交新的应用程序了。为了解决这个问题，spark提供了两种高可用性方案，分别是基于
zookeeper的HA方案以及基于文件系统的HA方案。

基于zookeeper的HA方案

概述

使用zookeeper来提供leader选举以及一些状态存储，你可以在集群中启动多个master进程，让它们连接到zookeeper实例。其中
一个master进程会被选举为leader，其他的master会被指定为standby模式。如果当前的leader master进程挂掉了，其他的
standby master会被选举，从而恢复旧master的状态。并且恢复作业调度。整个恢复过程（从leader master挂掉开始计算）大概
会花费1~2分钟。要注意的是，这只会推迟调度新的应用程序，master挂掉之前就运行的应用程序是不被影响的。

配置

如果要启用这个恢复模式，需要在spark-env.sh文件中，设置SPARK_DAEMON_JAVA_OPTS选项：

spark.deploy.recoveryMode		设置为ZOOKEEPER来启用standby master恢复模式（默认为NONE）
spark.deploy.zookeeper.url		zookeeper集群url（举例来说，192.168.0.103:2181,192.168.0.104:2181）
spark.deploy.zookeeper.dir		zookeeper中用来存储恢复状态的目录（默认是/spark）

备注：如果在集群中启动了多个master节点，但是没有正确配置master去使用zookeeper，master在挂掉进行恢复时是会失败的，
因为没法发现其他master，并且都会认为自己是leader。这会导致集群的状态不是健康的，因为所有master都会自顾自地去调度。

细节

在启动一个zookeeper集群之后，启用高可用性是很直接的。简单地在多个节点上启动多个master进程，并且给它们相同的zookeeper
配置（zookeeper url和目录）。master就可以被动态加入master集群，并可以在任何时间被移除掉。

为了调度新的应用程序或者向集群中添加worker节点，它们需要知道当前leader master的ip地址。这可以通过传递一个master列表
来完成。举例来说，我们可以将我们的SparkContext连接的地址指向spark://host1:port1,host2:port2。这就会导致你的
SparkContext尝试去注册所有的master，如果host1挂掉了，那么配置还是正确的，因为会找到新的leader master，也就是host2。

对于注册一个master和普通的操作，这是一个重要的区别。当一个应用程序启动的时候，或者worker需要被找到并且注册到当前
的leader master的时候。一旦它成功注册了，就被保存在zookeeper中了。如果故障发生了，new leader master会去联系所有的
之前注册过的应用程序和worker，并且通知它们master的改变。这样的话，它们甚至在启动的时候都不需要知道new master的存在。

正是由于这个属性，new master可以在任何时间被创建，并且我们唯一需要担心的一件事情就是新的应用程序和worker可以找到
并且注册到master。一旦注册上去之后，我们就不用担心它了。



# 第232讲-Spark运维管理进阶-实验：基于ZooKeeper实现HA高可用性以及自动主备切换

实验

1、将192.168.0.103机器上的spark集群先停止
./sbin/stop-all.sh

2、修改机器上的spark-env.sh文件，在其中加入上述三个属性
export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=192.168.0.103:2181,192.168.0.104:2181 -Dspark.deploy.zookeeper.dir=/spark"

3、启动集群
在192.168.0.103上直接用启动集群：./sbin/start-all.sh

4、在192.168.0.104上部署spark安装包，并启动一个master进程

安装scala 2.11.4

1、将课程提供的scala-2.11.4.tgz使用WinSCP拷贝到/usr/local/src目录下。
2、对scala-2.11.4.tgz进行解压缩：tar -zxvf scala-2.11.4.tgz
3、对scala目录进行重命名：mv scala-2.11.4 scala
4、配置scala相关的环境变量
vi ~/.bashrc
export SCALA_HOME=/usr/local/scala
export PATH=$SCALA_HOME/bin
source ~/.bashrc
5、查看scala是否安装成功：scala -version

安装spark客户端

1、将spark-1.5.1-bin-hadoop2.4.tgz使用WinSCP上传到/usr/local/src目录下。
2、解压缩spark包：tar -zxvf spark-1.5.1-bin-hadoop2.4.tgz。
3、重命名spark目录：mv spark-1.5.1-bin-hadoop2.4 spark
4、修改spark环境变量
vi ~/.bashrc
export SPARK_HOME=/usr/local/spark
export PATH=$SPARK_HOME/bin
export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib
source ~/.bashrc

修改spark-env.sh文件

1、cd /usr/local/spark/conf
2、cp spark-env.sh.template spark-env.sh
3、vi spark-env.sh
export JAVA_HOME=/usr/java/latest
export SCALA_HOME=/usr/local/scala
export HADOOP_HOME=/usr/local/hadoop
export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
export SPARK_MASTER_IP=192.168.0.104
export SPARK_DAEMON_MEMORY=100m
export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=192.168.0.103:2181,192.168.0.104:2181 -Dspark.deploy.zookeeper.dir=/spark"

在192.168.0.104上单独启动一个standby master进程：./sbin/start-master.sh

4、提交应用程序
将master地址修改为192.168.0.103:7077,192.168.0.103:7078

5、杀掉原先的leader master，等到standby master接管集群
再次提交应用程序

6、再次手动启动原来的leader master（死掉）



# 第233讲-Spark运维管理进阶-基于文件系统实现HA高可用性以及手动主备切换

概述

zookeeper是实现生产级别的高可用性的最佳方式，但是如果你就是想要在master进程挂掉的时候，手动去重启它，而不是依靠
zookeeper实现自动主备切换，那么可以使用FILESYSTEM模式。当应用程序和worker都注册到master之后，master就会将它们的信息
写入指定的文件系统目录中，以便于当master重启的时候可以从文件系统中恢复注册的应用程序和worker状态。

配置

要启用这种恢复模式，需要在spark-env.sh中设置SPARK_DAEMON_JAVA_OPTS

spark.deploy.recoveryMode		设置为FILESYSTEM来启用单点恢复（默认值为NONE）
spark.deploy.recoveryDirectory	spark在哪个文件系统目录内存储状态信息，必须是master可以访问的目录

细节

1、这个解决方案可以与进程监控或管理器（比如monit）结合使用，或者就仅仅是启用手动重启恢复机制即可。
2、文件系统恢复比不做任何恢复机制肯定是要好的，这个模式更加适合于开发和测试环境，而不是生产环境。此外，通过
stop-master.sh脚本杀掉一个master进程是不会清理它的恢复状态的，所以当你重启一个新的master进程时，它会进入恢复模式。
这会增加你的恢复时间至少1分钟，因为它需要等待之前所有已经注册的worker等节点先timeout。
3、这种方式没有得到官方的支持，也可以使用一个NFS目录作为恢复目录。如果原先的master节点完全死掉了，你可以在其他节点
上启动一个master进程，它会正确地恢复之前所有注册的worker和应用程序。之后的应用程序可以找到新的master，然后注册。



# 第234讲-Spark运维管理进阶-实验：基于文件系统实现HA高可用性以及手动主备切换

1、关闭两台机器上的master和worker
2、修改192.168.0.103机器上的spark-env.sh
export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=FILESYSTEM -Dspark.deploy.recoveryDirectory=/usr/local/spark_recovery"
3、在192.168.0.103上启动spark集群
4、在spark-shell中进行wordcount计数，到一半，有一个running application
5、杀掉master进程
6、重启master进程
7、观察web ui上，是否恢复了worker以及原先正在运行的application


# 第235讲-Spark运维管理进阶-作业监控-实验：通过Spark Web UI进行作业监控

对于Spark作业的监控，Spark给我们提供了很多种方式：Spark Web UI，Spark History Web UI，RESTFUL API以及Metrics。

这里我们就先来看看如何通过Spark Web UI监控作业的运行。

Spark Web UI

每提交一个Spark作业，并且启动SparkContext之后，都会启动一个对应的Spark Web UI服务。默认情况下Spark Web UI的访问地址是
driver进程所在节点的4040端口。在Spark Web UI上会展示作业相关的详细信息，非常有用，是Spark作业监控的最主要的手段。

Spark Web UI包括了以下信息：

1、stage和task列表
2、RDD大小以及内存使用的概览
3、环境信息
4、作业对应的executor的信息

可以通过在浏览器中访问http://<driver-node>:4040地址，来进入Spark Web UI界面。如果多个driver在一个机器上运行，它们
会自动绑定到不同的端口上。默认从4040端口开始，如果发现已经被绑定了，那么会选择4041、4042等端口，以此类推。

要注意的是，这些信息默认情况下仅仅在作业运行期间有效并且可以看到。一旦作业完毕，那么driver进程以及对应的web ui服务
也会停止，我们就无法看到已经完成的作业的信息了。如果要在作业完成之后，也可以看到其Spark Web UI以及详细信息，那么就
需要启用Spark的History Server。

监控实验

1、通过spark-shell以standalone模式执行一个wordcount作业，通过直接访问4040端口以及从8080端口两种方式进入web ui。
2、在作业运行完毕之后，再尝试看看作业的Web UI。
3、通过spark-shell以yarn模式执行一个wordcount作业，并重复上述过程。



# 第236讲-Spark运维管理进阶-作业监控-实验：standalone模式下查看历史作业的Web UI

默认情况下，一个作业运行完成之后，就再也无法看到其web ui以及执行信息了，在生产环境中，这对调试以及故障定位有影响。

如果要在作业执行完之后，还能看到其web ui，那么必须将作业的spark.eventLog.enabled属性设置为true，这个属性会告诉spark
去记录该作业的所有要在web ui上展示的事件以及信息。

如果spark记录下了一个作业生命周期内的所有事件，那么就会在该作业执行完成之后，我们进入其web ui时，自动用记录的数据
重新绘制作业的web ui。

有3个属性我们可以设置

1、spark.eventLog.enabled，必须设置为true
2、spark.eventLog.dir，默认是/tmp/spark-events，建议自己手动调整为其他目录，比如/usr/local/spark-event或是hdfs目录，必须手动创建
3、spark.eventLog.compress ，是否压缩数据，默认为false，建议可以开启压缩以减少磁盘空间占用

这些属性可以在提交一个作业的时候设置
如果想要对所有作业都启用该机制，那么可以在spark-defaults.conf文件中配置这三个属性

实验

1、先看看之前的已经执行完成的作业，是否可以进入spark web ui界面
2、关闭现有的master和worker进程
3、修改spark-defaults.conf文件，配置上述三个属性，启用standalone模式下的作业历史信息记录，手动创建hdfs目录
4、重新启动spark集群
5、使用spark-shell提交一个作业，然后再次尝试进入spark web ui界面

注意：如果要让spark完成作业的事件记录，那么必须最后以sc.stop()结尾。



# 第237讲-Spark运维管理进阶-作业监控-实验：启动HistoryServer查看历史作业的Web UI

spark-defaults.conf

spark.eventLog.enabled  true
spark.eventLog.dir      hdfs://192.168.0.103:9000/spark-events
spark.eventLog.compress true

spark-env.sh

export SPARK_HISTORY_OPTS="-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=50 -Dspark.history.fs.logDirectory=hdfs://192.168.0.103:9000/spark-events"

务必预先创建好hdfs://192.168.0.103:9000/spark-events目录
而且要注意，spark.eventLog.dir与spark.history.fs.logDirectory指向的必须是同一个目录
因为spark.eventLog.dir会指定作业事件记录在哪里，spark.history.fs.logDirectory会指定从哪个目录中去读取作业数据

启动HistoryServer: ./sbin/start-history-server.sh

访问地址: 192.168.0.103:18080

实验

1、停止集群
2、配置spark-env.sh
3、重启集群
4、启动history server
5、运行spark-shell，在standalone模式下和yarn模式下，分别执行一个作业
6、通过192.168.80.103:18080的HistoryServer UI可以看到所有运行后的作业信息



# 第238讲-Spark运维管理进阶-作业监控-实验：使用curl+REST API进行作业监控

除了查看ui上的统计来监控作业，还可以通过Spark提供的REST API来获取作业信息，并进行作业监控。REST API就给我们自己开发
Spark的一些监控系统或平台提供了可能。REST API是通过http协议发送的，并给我们返回JSON格式的数据。因此无论你是用java，
还是python，亦或是php，都可以获取Spark的监控信息。

运行中的作业以及history server中的历史作业，都可以获取到信息

1、如果是要获取运行中的作业的信息，可以通过http://host:4040/api/v1/...的方式来获取
2、如果是要获取历史作业的信息，可以通过http://host:18080/api/v1/...的方式来获取

比如说，http://192.168.0.103:18080/api/v1/applications，就可以获取到所有历史作业的基本信息

以下是所有API的说明

/applications																	获取作业列表
/applications/[app-id]/jobs														指定作业的job列表
/applications/[app-id]/jobs/[job-id]											指定job的信息
/applications/[app-id]/stages													指定作业的stage列表
/applications/[app-id]/stages/[stage-id]										指定stage的所有attempt列表
/applications/[app-id]/stages/[stage-id]/[stage-attempt-id]						指定stage attempt的信息
/applications/[app-id]/stages/[stage-id]/[stage-attempt-id]/taskSummary			指定stage attempt所有task的metrics统计信息
/applications/[app-id]/stages/[stage-id]/[stage-attempt-id]/taskList			指定stage attempt的task列表
/applications/[app-id]/executors												指定作业的executor列表
/applications/[app-id]/storage/rdd												指定作业的持久化rdd列表
/applications/[app-id]/storage/rdd/[rdd-id]										指定持久化rdd的信息
/applications/[app-id]/logs														下载指定作业的所有日志的压缩包
/applications/[app-id]/[attempt-id]/logs										下载指定作业的某次attempt的所有日志的压缩包

当作业运行在yarn中时，每个作业都可能会尝试多次运行，所以上述的所有[app-id]都必须替换为[app-id]/[attempt-id]

这些API都非常便于让我们去基于它们开发各种监控系统或应用。特别是，spark保证以下几点: 

1、API永远不会因为版本的变更而更改
2、JSON中的字段用于不会被移除
3、新的API接口可能会被增加
4、已有API接口中可能会增加新的字段
5、API的新版本可能会作为新接口被添加进来。新版本的接口不要求向后兼容。
6、API版本可能会被删除掉，但是肯定是在一个相关的新API版本发布之后。

要注意的是，当查看运行中作业的UI时，applications/[app-id]还是需要提供的，尽管此时在那个4040端口上可能只有一个
作业在运行。比如说，要查看正在运行的作业的job列表，可能需要使用以下API: http://host:4040/api/v1/applications/[app-id]/jobs
这主要是为了尽可能地复用API接口

实验

1、安装curl工具，来发送http请求: yum install -y curl
2、试一试以上的几个API，去获取standalone模式和yarn模式运行中的作业，以及历史作业的信息



# 第239讲-Spark运维管理进阶-作业监控-实验：Spark Metrics系统以及自定义Metrics Sink

Spark有一套可配置的metrics系统，是基于Coda Hale Metrics类库实现的。该metrics系统允许用户将Spark的metrics统计指标
上报到多种目标源（sink）中，包括http，jmx和csv文件。这个metrics系统是通过一个配置文件进行配置的，在$SPARK_HOME目录
的conf目录下，用一个metrics.properties文件来配置。可以通过在spark-defaults.conf中配置spark.metrics.conf属性来配置
自定义的文件路径。spark metrics依据不同的spark组件划分为了不同的实例。在每一个实例中，你都可以配置一系列的sink来
指定该实例的metrics要上报到哪里去。

以下实例是目前被支持的

master: spark standalone master进程
applications: master中的组件，可以上报所有application的metrics
worker: spark standalone worker进程
executor: spark executor进程
driver: spark driver进程

每个实例都可以上报metrics到0个或多个sink中。sink被包含在了org.apache.spark.metrics.sink包下。

ConsoleSink: 日志metrics，打印到控制台
CSVSink: 以固定的频率将metrics数据导出到CSV文件中
JmxSink: 注册metrics到JMX console中
MetricsServlet: 在Spark UI中添加一个servlet来通过JSON数据提供metrics数据（之前的REST API就是通过该方式进行的）
Slf4jSink: 以日志的形式发送metrics到slf4j

GraphiteSink: 发送metrics到Graphite节点

Spark也支持Ganglia sink，但是没有包含在默认的打包内，因为有版权的问题。
GangliaSink: 发送metrics到Ganglia节点。
要安装GangliaSink，就需要自己编译一个spark。要注意，必须要提供必要的授权信息。

metrics系统的意义

1、metrics只能在spark web ui上看到，或者是history server上看历史作业的web ui。
2、如果你希望将metrics数据，结构化处理以后导入到，比如mysql里面，然后进行一个存储，开发一个系统对外开放
3、spark集群运行分析系统
4、自定义metrics sink，将所有的metrics全部写入外部的你指定的存储文件中，然后定时导入到你的mysql中

实验: 自定义metrics sink

1、停止集群
2、配置spark.metrics.conf文件，启用CSVSink
3、重启集群
4、运行一个作业，查看指定目录下的csv文件


# 第240讲-Spark运维管理进阶-作业资源调度-静态资源分配原理

spark提供了许多功能用来在集群中同时调度多个作业。首先，回想一下，每个spark作业都会运行自己独立的一批executor进程，
此时集群管理器会为我们提供同时调度多个作业的功能。第二，在每个spark作业内部，多个job也可以并行执行，比如说
spark-shell就是一个spark application，但是随着我们输入scala rdd action类代码，就会触发多个job，多个job是可以并行执行的。
为这种情况，spark也提供了不同的调度器来在一个application内部调度多个job。

我们先来看一下多个作业的同时调度

静态资源分配

当一个spark application运行在集群中时，会获取一批独立的executor进程专门为自己服务，比如运行task和存储数据。如果多个
用户同时在使用一个集群，并且同时提交多个作业，那么根据cluster manager的不同，有几种不同的方式来管理作业间的资源分配。

最简单的一种方式，是所有cluster manager都提供的，也就是静态资源分配。在这种方式下，每个作业都会被给予一个它能使用的
最大资源量的限额，并且可以在运行期间持有这些资源。这是spark standalone集群和YARN集群使用的默认方式。

Standalone集群: 默认情况下，提交到standalone集群上的多个作业，会通过FIFO的方式来运行，每个作业都会尝试获取所有的
资源。可以限制每个作业能够使用的cpu core的最大数量（spark.cores.max），或者设置每个作业的默认cpu core使用量
（spark.deploy.defaultCores）。最后，除了控制cpu core之外，每个作业的spark.executor.memory也用来控制它的最大内存
的使用。

YARN: --num-executors属性用来配置作业可以在集群中分配到多少个executor，--executor-memory和--executor-cores可以控制
每个executor能够使用的资源。

要注意的是，没有一种cluster manager可以提供多个作业间的内存共享功能。如果你想要通过这种方式来在多个作业间共享数据，
我们建议就运行一个spark作业，但是可以接收网络请求，并对相同RDD的进行计算操作。在未来的版本中，内存存储系统，比如
Tachyon会提供其他的方式来共享RDD数据。

# 第241讲-Spark运维管理进阶-作业资源调度-动态资源分配原理
动态资源分配

spark 1.2开始，引入了一种根据作业负载动态分配集群资源给你的多个作业的功能。这意味着你的作业在申请到了资源之后，
可以在使用完之后将资源还给cluster manager，而且可以在之后有需要的时候再次申请这些资源。这个功能对于多个作业在集群
中共享资源是非常有用的。如果部分资源被分配给了一个作业，然后出现了空闲，那么可以还给cluster manager的资源池中，
并且被其他作业使用。在spark中，动态资源分配在executor粒度上被实现，可以通过spark.dynamicAllocation.enabled来启用。

资源分配策略

以一个较高的角度来说，当executor不再被使用的时候，spark就应该释放这些executor，并且在需要的时候再次获取这些executor。
因为没有一个绝对的方法去预测一个未来可能会运行一个task的executor应该被移除掉，或者一个新的executor应该别加入，我们
需要一系列的探索式算法来决定什么应该移除和申请executor。

申请策略

一个启用了动态资源分配的spark作业会在它有pending住的task等待被调度时，申请额外的executor。这个条件必要地暗示了，已经
存在的executor是不足以同时运行所有的task的，这些task已经提交了，但是没有完成。

driver会轮询式地申请executor。当在一定时间内（spark.dynamicAllocation.schedulerBacklogTimeout）有pending的task时，
就会触发真正的executor申请，然后每隔一定时间后（spark.dynamicAllocation.sustainedSchedulerBacklogTimeout），如果
又有pending的task了，则再次触发申请操作。此外，每一轮申请到的executor数量都会比上一轮要增加。举例来说，一个作业需要
增加一个executor在第一轮申请时，那么在后续的一轮中会申请2个、4个、8个executor。

每轮增加executor数量的原因主要有两方面。第一，一个作业应该在开始谨慎地申请以防它只需要一点点executor就足够了。第二，
作业应该会随着时间的推移逐渐增加它的资源使用量，以防突然大量executor被增加进来。

移除策略

移除一个executor的策略比较简单。一个spark作业会在它的executor出现了空闲超过一定时间后（spark.dynamicAllocation.executorIdleTimeout），
被移除掉。要注意，在大多数环境下，这个条件都是跟申请条件互斥的，因为如果有task被pending住的话，executor是不该是空闲的。

executor如何优雅地被释放掉

在使用动态分配之前，executor无论是发生了故障失败，还是关联的application退出了，都还是存在的。在所有场景中，executor
关联的所有状态都不再被需要，并且可以被安全地抛弃。使用动态分配之后，executor移除之后，作业还是存在的。如果作业尝试
获取executor写的中间状态数据，就需要去重新计算哪些数据。因此，spark需要一种机制来优雅地卸载executor，在移除它之前要
保护它的状态。

解决方案就是使用一个外部的shuffle服务来保存每个executor的中间写状态，这也是spark 1.2引入的特性。这个服务是一个长
时间运行的进程，集群的每个节点上都会运行一个，位你的spark作业和executor服务。如果服务被启用了，那么spark executor
会在shuffle write和read时，将数据写入该服务，并从该服务获取数据。这意味着所有executor写的shuffle数据都可以在executor
声明周期之外继续使用。

除了写shuffle文件，executor也会在内存或磁盘中持久化数据。当一个executor被移除掉时，所有缓存的数据都会消失。目前还没有
有效的方案。在未来的版本中，缓存的数据可能会通过堆外存储来进行保存，就像external shuffle service保存shuffle write
文件一样。


# 第242讲-Spark运维管理进阶-作业资源调度-实验：standalone模式下使用动态资源分配

./sbin/.start-shuffle-service.sh

--conf spark.shuffle.service.enabled=true \
--conf spark.dynamicAllocation.enabled=true \
--conf spark.shuffle.service.port=7337 \

1、启动external shuffle service
2、启动spark-shell，启用动态资源分配
3、过60s，发现打印日志，说executor被removed，executor进程也没了
4、然后动手写一个wordcount程序，最后提交job的时候，会动态申请一个新的executor，出来一个新的executor进程
5、然后整个作业执行完毕，证明external shuffle service+动态资源分配，流程可以走通
6、再等60s，executor又被释放掉


# 第243讲-Spark运维管理进阶-作业资源调度-实验：yarn模式下使用动态资源分配

先停止之前为standalone集群启动的shuffle service，./sbin/stop-shuffle-service.sh

配置

动态资源分配功能使用的所有配置，都是以spark.dynamicAllocation作为前缀的。要启用这个功能，你的作业必须将
spark.dynamicAllocation.enabled设置为true。其他相关的配置之后会详细说明。

此外，你的作业必须有一个外部shuffle服务（external shuffle service）。这个服务的目的是去保存executor的shuffle write
文件，从而让executor可以被安全地移除。要启用这个服务，可以将spark.shuffle.service.enabled设置为true。在YARN中，这个
外部shuffle service是由org.apache.spark.yarn.network.YarnShuffleService实现的，在每个NodeManager中都会运行。要启用
这个服务，需要使用以下步骤：

1、使用预编译好的spark版本。
2、定位到spark-<version>-yarn-shuffle.jar。这个应该在$SPARK_HOME/lib目录下。
3、将上面的jar加入到所有NodeManager的classpath中。
4、在yarn-site.xml中，将yarn.nodemanager.aux-services设置为spark_shuffle，将yarn.nodemanager.aux-services.spark_shuffle.class设置为org.apache.spark.network.yarn.YarnShuffleService
5、重启所有NodeManager

--conf spark.shuffle.service.enabled=true \
--conf spark.dynamicAllocation.enabled=true \
--conf spark.shuffle.service.port=7337 \

1、首先配置好yarn的shuffle service，然后重启集群
2、接着呢，启动spark shell，并启用动态资源分配，但是这里跟standalone不一样，上来不会立刻申请executor
3、接着执行wordcount，会尝试动态申请executor，并且申请到后，执行job，在spark web ui上，有两个executor
4、过了一会儿，60s过后，executor由于空闲，所以自动被释放掉了，在看spark web ui，没有executor了


# 第244讲-Spark运维管理进阶-作业资源调度-多个job资源调度原理

在一个spark作业内部，多个并行的job是可以同时运行的。对于job，就是一个spark action操作触发的计算单元。spark的调度器
是完全线程安全的，而且支持一个spark application来服务多个网络请求，以及并发执行多个job。

默认情况下，spark的调度会使用FIFO的方式来调度多个job。每个job都会被划分为多个stage，而且第一个job会对所有可用的资源
获取优先使用权，并且让它的stage的task去运行，然后第二个job再获取资源的使用权，以此类推。如果队列头部的job不需要使用
整个集群资源，之后的job可以立即运行，但是如果队列头部的job使用了集群几乎所有的资源，那么之后的job的运行会被推迟。

从spark 0.8开始，我们是可以在多个job之间配置公平的调度器的。在公平的资源共享策略下，spark会将多个job的task使用一种
轮询的方式来分配资源和执行，所以所有的job都有一个基本公平的机会去使用集群的资源。这就意味着，即使运行时间很长的job
先提交并在运行了，之后提交的运行时间较短的job，也同样可以立即获取到资源并且运行，而不会等待运行时间很长的job结束之后
才能获取到资源。这种模式对于多个并发的job是最好的一种调度方式。

# 第245讲-Spark运维管理进阶-作业资源调度-Fair Scheduler使用详解

要启用Fair Scheduler，只要简单地将spark.scheduler.mode属性设置为FAIR即可

val conf = new SparkConf().setMaster(...).setAppName(...)
conf.set("spark.scheduler.mode", "FAIR")
val sc = new SparkContext(conf)

或者

--conf spark.scheduler.mode=FAIR

fair scheduler也支持将job分成多个组并放入多个池中，以及为每个池设置不同的调度优先级。这个feature对于将重要的和不重要
的job隔离运行的情况非常有用，可以为重要的job分配一个池，并给予更高的优先级; 为不重要的job分配另一个池，并给予较低的
优先级。

默认情况下，新提交的job会进入一个默认池，但是job的池是可以通过spark.scheduler.pool属性来设置的。

如果你的spark application是作为一个服务启动的，SparkContext 7*24小时长时间存在，然后服务每次接收到一个请求，就用一个子线程去服务它
在子线程内部，去执行一系列的RDD算子以及代码来触发job的执行
在子线程内部，可以调用SparkContext.setLocalProperty("spark.scheduler.pool", "pool1")

在设置这个属性之火，所有在这个线程中提交的job都会进入这个池中。同样也可以通过将该属性设置为null来清空池子。

池的默认行为

默认情况下，每个池子都会对集群资源有相同的优先使用权，但是在每个池内，job会使用FIFO的模式来执行。举例来说，如果
要为每个用户创建一个池，这就意味着每个用户都会获得集群的公平使用权，但是每个用户自己的job会按照顺序来执行。

配置池的属性

可以通过配置文件来修改池的属性。每个池都支持以下三个属性: 

1、schedulingMode: 可以是FIFO或FAIR，来控制池中的jobs是否要排队，或者是共享池中的资源
2、weight: 控制每个池子对集群资源使用的权重。默认情况下，所有池子的权重都是1.如果指定了一个池子的权重为2。举例来说，
它就会获取其他池子两倍的资源使用权。设置一个很高的权重值，比如1000，也会很有影响，基本上该池子的task会在其他所有池子
的task之前运行。
3、minShare: 除了权重之外，每个池子还能被给予一个最小的资源使用量。

池子的配置是通过xml文件来配置的，在spark/conf的fairscheduler.xml中配置
我们自己去设置这个文件的路径，conf.set("spark.scheduler.allocation.file", "/path/to/file")

文件内容大致如下所示

<?xml version="1.0"?>
<allocations>
  <pool name="production">
    <schedulingMode>FAIR</schedulingMode>
    <weight>1</weight>
    <minShare>2</minShare>
  </pool>
  <pool name="test">
    <schedulingMode>FIFO</schedulingMode>
    <weight>2</weight>
    <minShare>3</minShare>
  </pool>
</allocations>
