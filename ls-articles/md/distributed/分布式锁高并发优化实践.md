---
title: 分布式锁高并发优化实践
categories: 
- 分布式
tags:
---


#在高并发场景下如何优化分布式锁的并发性能

##1、背景引入

库存超卖现象是怎么产生的？
先来看看如果不用分布式锁，所谓的电商库存超卖是啥意思？大家看看下面的图：
<div align="center"> <img src="../../pics/分布式锁高并发优化实践1.png"/> </div><br>

这个图，其实很清晰了，假设订单系统部署两台机器上，不同的用户都要同时买10台iphone，分别发了一个请求给订单系统。
接着每个订单系统实例都去数据库里查了一下，当前iphone库存是12台。
俩大兄弟一看，乐了，12台库存大于了要买的10台数量啊！
于是乎，每个订单系统实例都发送SQL到数据库里下单，然后扣减了10个库存，其中一个将库存从12台扣减为2台，另外一个将库存从2台扣减为-8台。
现在完了，库存出现了负数！泪奔啊，没有20台iphone发给两个用户啊！这可如何是好。

##2、用分布式锁如何解决库存超卖问题？
我们用分布式锁如何解决库存超卖问题呢？其实很简单，回忆一下上次我们说的那个分布式锁的实现原理：
<div align="center"> <img src="../../pics/分布式锁高并发优化实践2.png"/> </div><br>

同一个锁key，同一时间只能有一个客户端拿到锁，其他客户端会陷入无限的等待来尝试获取那个锁，只有获取到锁的客户端才能执行下面的业务逻辑。
代码大概就是上面那个样子，现在我们来分析一下，为啥这样做可以避免库存超卖？
<div align="center"> <img src="../../pics/分布式锁高并发优化实践3.png"/> </div><br>

大家可以顺着上面的那个步骤序号看一遍，马上就明白了。
从上图可以看到，只有一个订单系统实例可以成功加分布式锁，然后只有他一个实例可以查库存、判断库存是否充足、下单扣减库存，接着释放锁。
释放锁之后，另外一个订单系统实例才能加锁，接着查库存，一下发现库存只有2台了，库存不足，无法购买，下单失败。不会将库存扣减为-8的。

##3、有没有其他方案可以解决库存超卖问题？

当然有啊！比如悲观锁，分布式锁，乐观锁，队列串行化，异步队列分散，Redis原子操作，等等。
但是前面说过了，这篇文章就聊一个分布式锁的并发优化，不是聊库存超卖的解决方案，所以库存超卖只是一个业务场景而已。
分布式锁的方案在高并发场景下有什么问题？

问题很大啊！兄弟，不知道你看出来了没有。分布式锁一旦加了之后，对同一个商品的下单请求，
会导致所有客户端都必须对同一个商品的库存锁key进行加锁。
比如，对iphone这个商品的下单，都必对“iphone_stock”这个锁key来加锁。
这样会导致对同一个商品的下单请求，就必须串行化，一个接一个的处理。
大家再回去对照上面的图反复看一下，应该能想明白这个问题。
假设加锁之后，释放锁之前，查库存 -> 创建订单 -> 扣减库存，这个过程性能很高吧，算他全过程20毫秒，这应该不错了。
那么1秒是1000毫秒，只能容纳50个对这个商品的请求依次串行完成处理。
比如一秒钟来50个请求，都是对iphone下单的，那么每个请求处理20毫秒，一个一个来，最后1000毫秒正好处理完50个请求。
大家看一眼下面的图，加深一下感觉。
<div align="center"> <img src="../../pics/分布式锁高并发优化实践4.png"/> </div><br>

所以看到这里，大家起码也明白了，简单的使用分布式锁来处理库存超卖问题，存在什么缺陷。
缺陷就是同一个商品多用户同时下单的时候，会基于分布式锁串行化处理，导致没法同时处理同一个商品的大量下单的请求。
这种方案，要是应对那种低并发、无秒杀场景的普通小电商系统，可能还可以接受。
因为如果并发量很低，每秒就不到10个请求，没有瞬时高并发秒杀单个商品的场景的话，
其实也很少会对同一个商品在一秒内瞬间下1000个订单，因为小电商系统没那场景。

##4、如何对分布式锁进行高并发优化？

库存超卖就是用分布式锁来解决，而且一秒对一个iphone下上千订单，怎么优化？
现在按照刚才的计算，你一秒钟只能处理针对iphone的50个订单。
其实说出来也很简单，相信很多人看过java里的ConcurrentHashMap的源码和底层原理，应该知道里面的核心思路，就是分段加锁！
把数据分成很多个段，每个段是一个单独的锁，所以多个线程过来并发修改数据的时候，可以并发的修改不同段的数据。
不至于说，同一时间只能有一个线程独占修改ConcurrentHashMap中的数据。
另外，Java 8中新增了一个LongAdder类，也是针对Java 7以前的AtomicLong进行的优化，解决的是CAS类操作在高并发场景下，
使用乐观锁思路，会导致大量线程长时间重复循环。
LongAdder中也是采用了类似的分段CAS操作，失败则自动迁移到下一个分段进行CAS的思路。
其实分布式锁的优化思路也是类似的，之前我们是在另外一个业务场景下落地了这个方案到生产中，不是在库存超卖问题里用的。
但是库存超卖这个业务场景不错，很容易理解，所以我们就用这个场景来说一下。大家看看下面的图：
<div align="center"> <img src="../../pics/分布式锁高并发优化实践5.png"/> </div><br>

其实这就是分段加锁。你想，假如你现在iphone有1000个库存，那么你完全可以给拆成20个库存段，
要是你愿意，可以在数据库的表里建20个库存字段，比如stock_01，stock_02，类似这样的，也可以在redis之类的地方放20个库存key。
总之，就是把你的1000件库存给他拆开，每个库存段是50件库存，比如stock_01对应50件库存，stock_02对应50件库存。
接着，每秒1000个请求过来了，好！此时其实可以是自己写一个简单的随机算法，每个请求都是随机在20个分段库存里，选择一个进行加锁。
这样就好了，同时可以有最多20个下单请求一起执行，每个下单请求锁了一个库存分段，然后在业务逻辑里面，
就对数据库或者是Redis中的那个分段库存进行操作即可，包括查库存 -> 判断库存是否充足 -> 扣减库存。
这相当于什么呢？相当于一个20毫秒，可以并发处理掉20个下单请求，那么1秒，也就可以依次处理掉20 * 50  = 1000个对iphone的下单请求了。

- 一旦对某个数据做了分段处理之后，有一个坑大家一定要注意：
    就是如果某个下单请求，咔嚓加锁，然后发现这个分段库存里的库存不足了，此时咋办？
这时你得自动释放锁，然后立马换下一个分段库存，再次尝试加锁后尝试处理。这个过程一定要实现。

##5、分布式锁并发优化方案有没有什么不足？

不足肯定是有的，最大的不足，大家发现没有，很不方便啊！实现太复杂了。
首先，你得对一个数据分段存储，一个库存字段本来好好的，现在要分为20个分段库存字段；
其次，你在每次处理库存的时候，还得自己写随机算法，随机挑选一个分段来处理；
最后，如果某个分段中的数据不足了，你还得自动切换到下一个分段数据去处理。
这个过程都是要手动写代码实现的，还是有点工作量，挺麻烦的。
不过我们确实在一些业务场景里，因为用到了分布式锁，然后又必须要进行锁并发的优化，
又进一步用到了分段加锁的技术方案，效果当然是很好的了，一下子并发性能可以增长几十倍。



##6、问题

用分布式锁的分段加锁的方式，解决库存超卖问题，那如果一个分段的库存不满足要购买的数量，怎么办？

如果一个分段库存不足，要锁其他的分段，进行合并扣减，如果你做分段加锁，那就是这样的，很麻烦。
如果大家去看看Java 8里的LongAdder的源码，他的分段加锁的优化，也是如此的麻烦，要做段迁移。
