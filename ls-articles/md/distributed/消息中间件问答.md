---
title: 消息中间件问答
categories: 
- 分布式
tags:
---


#问题
- 1、你们公司生产环境用的是什么消息中间件？
- 2、为什么要在系统里引入消息中间件？
- 3、引入消息中间件之后会有什么好处以及坏处？缺点
- 4、使用场景
- 5、初步落地
- 6、线上服务宕机时，如何保证数据100%不丢失？

## 1、你们公司生产环境用的是什么消息中间件？
这个首先你可以说下你们公司选用的是什么消息中间件，比如用的是RabbitMQ，
然后可以初步给一些你对不同MQ中间件技术的选型分析。

举个例子：比如说ActiveMQ是老牌的消息中间件，国内很多公司过去运用的还是非常广泛的，功能很强大。
但是问题在于没法确认ActiveMQ可以支撑互联网公司的高并发、高负载以及高吞吐的复杂场景，
在国内互联网公司落地较少。而且使用较多的是一些传统企业，用ActiveMQ做异步调用和系统解耦。

然后你可以说说RabbitMQ，他的好处在于可以支撑高并发、高吞吐、性能很高，同时有非常完善便捷的后台管理界面可以使用。
另外，他还支持集群化、高可用部署架构、消息高可靠支持，功能较为完善。
而且经过调研，国内各大互联网公司落地大规模RabbitMQ集群支撑自身业务的case较多，
国内各种中小型互联网公司使用RabbitMQ的实践也比较多。

除此之外，RabbitMQ的开源社区很活跃，较高频率的迭代版本，来修复发现的bug以及进行各种优化，因此综合考虑过后，公司采取了RabbitMQ。
但是RabbitMQ也有一点缺陷，就是他自身是基于erlang语言开发的，所以导致较为难以分析里面的源码，也较难进行深层次的源码定制和改造，
毕竟需要较为扎实的erlang语言功底才可以。

然后可以聊聊RocketMQ，是阿里开源的，经过阿里的生产环境的超高并发、高吞吐的考验，性能卓越，同时还支持分布式事务等特殊场景。
而且RocketMQ是基于Java语言开发的，适合深入阅读源码，有需要可以站在源码层面解决线上生产问题，包括源码的二次开发和改造。

另外就是Kafka。Kafka提供的消息中间件的功能明显较少一些，相对上述几款MQ中间件要少很多。
但是Kafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。
因此Kafka在大数据领域中配合实时计算技术（比如Spark Streaming、Storm、Flink）使用的较多。
但是在传统的MQ中间件使用场景中较少采用。

PS：如果大家对上述一些MQ技术还没在自己电脑部署过，没写几个helloworld体验一下的话，建议先上各个技术的官网找到helloworld demo，
自己跑一遍玩玩

## 2、为什么在你们系统架构中要引入消息中间件？
1）系统解耦 [多个系统以来一份数据]
2）异步调用[点外卖，下单和配送服务]
3）流量削峰[秒杀]
4）日志采集[多个数据源]

## 3、缺点
1）系统可用性降低[MQ挂掉之后的高可用保障方案]
2）系统稳定性降低[消息高可靠传递（0丢失），消息幂等性传递（绝对不重复），百万消息积压的线上故障处理]
3）分布式一致性问题[本地事务成功，MQ失败，导致数据不一致]

## 4、使用场景

业务场景的话，咱们就用大家都很熟悉的电商业务为例，这里为了便于理解，对其做了一定的抽象和简化。
大家还是来考虑一个下订单的业务流程，比如你下个订单，此时需要干几件事情：
- 更新订单状态为“待发货”（耗时20ms）
- 扣减商品库存（耗时100ms）
- 增加会员积分（耗时80ms）
- 附赠优惠券（耗时50ms）
- 仓储调度发货（耗时几十秒）。

说明一下：上述环节，为了便于大家理解，做了简化。实际真正复杂的电商系统里，整体环节和业务流程会比这个复杂很多倍，
而且耗时也绝对不是上面那么简单的。通过一张手绘图，来看看这整个的业务流程：
<div align="center"> <img src="../../pics/mq问答1.png"/> </div><br>

如上图，这个下订单的业务流程中：
更新订单状态（20ms） +  扣减商品库存（100ms） +  增加会员积分（80ms） +  附赠优惠券（50ms） =  250ms。
也就是说，仅仅是这4个流程的话，也就200多毫秒的耗时。
200多毫秒的耗时，对用户下单体验来说是非常快速的，几乎就是一瞬间就完成了，不会感到过多的停顿，也就是一下子就可以看到自己下单成功了。
但是，如果加上那个调度仓储发货呢？
那个环节需要读取大量的数据、使用多仓库/多货位的调度算法、还要跟C/S架构的仓储系统进行网络通信，因此我们这里假设这个环节可能会耗时数十秒。
一旦加上那个调度仓储发货的环节到这个下单流程里，就可能导致用户要等页面卡顿几十秒后才会看到下单成功的提示，这个用户体验就相当的差了。
[对于这种场景，完全适合使用消息中间件来进行异步化调用]
也就是说，订单服务对仓储调度发货，仅仅是发送一个消息到MQ里，然后仓储服务消费消息之后再慢慢的执行调度算法，
然后分配商品发货任务给对应的仓库即可。
这样的话，就可以把耗时几十秒的仓储调度发货的环节，从下单流程里摘除出去了。进而保证下单流程就仅仅是耗时200多毫秒而已。
至于那个耗时几十秒的仓储调度发货环节，我们通过异步的方式慢慢执行即可，不会影响用户下单的体验。
以上过程，来一张图，大家直观的感受一下：
<div align="center"> <img src="../../pics/mq问答2.png"/> </div><br>


## 5、初步落地

好！接下来我们就假设大家在实际生产中还没用过消息中间件，咱们从0开始，看看如何落地？
我们以RabbitMQ为例，假如你用的消息中间件是RabbitMQ，那么我们对这个消息中间件应该如何安装和部署呢？
很简单，RabbitMQ的官方文档里提供了非常详细的安装部署步骤，你可以在自己的笔记本电脑本地安装，也可以在公司的服务器上部署。
现在假设你已经参考了官方文档并安装完成，那么接下来在代码层面应该怎么来引入RabbitMQ以及在系统里实现收发消息呢？
下面通过一些HelloWorld级别的代码和一些简单的示例图，给大家演示一下RabbitMQ是如何收发消息的。
<div align="center"> <img src="../../pics/mq问答3.png"/> </div><br>
<div align="center"> <img src="../../pics/mq问答4.png"/> </div><br>
<div align="center"> <img src="../../pics/mq问答5.png"/> </div><br>
<div align="center"> <img src="../../pics/mq问答6.png"/> </div><br>

好！看完了代码，这个时候，我们可以通过一张图来想象一下两个服务之间的通信。
订单服务你可以启动多个，不同的订单服务都可以往一个RabbitMQ的queue里推送消息。
仓储服务你也可以启动多个，多个仓储服务会采用round-robin的轮询算法，每个服务实例都可以从RabbitMQ queue里消费到一部分的消息。
<div align="center"> <img src="../../pics/mq问答7.png"/> </div><br>

上面的图里，订单服务在MQ专业术语中叫做“生产者”，英文是“Producer”，意思就是这个服务是专门负责生产消息投递到MQ的。
仓储服务在MQ专业术语中叫做“消费者”，英文是“Consumer”，意思就是这个服务专门是负责从MQ消费消息然后处理的。
这个时候，这套异步通信的架构就可以跑起来了。

## 6、线上服务宕机时，如何保证数据100%不丢失？

看看订单服务和消息服务是如何基于MQ来收发消息的。
我们稍微把这个图细化一点，简单来说就是多个订单服务实例给queue推送消息，多个仓储服务每个消费一部分消息。如下图所示：
<div align="center"> <img src="../../pics/mq问答8.png"/> </div><br>

那你说说如果仓储服务作为消费者服务，刚收到了一个订单消息，但是在完成消息的处理之前，也就是还没对订单完成仓储调度发货，
结果这个仓储服务突然就宕机了，这个时候会发生什么事情？
先来看看下面的图，感受一下车祸现场。
<div align="center"> <img src="../../pics/mq问答9.png"/> </div><br>

RabbitMQ这个中间件默认的一个行为，就是只要仓储服务收到一个订单消息，RabbitMQ就会立马把这条订单消息给标记为删除，这个行为叫做自动ack，
也就是投递完成一条消息就自动确认这个消息处理完毕了。
但是接着如果此时仓储服务收到了一个订单消息，但是还没来得及对仓库系统完成商品的调度发货，结果直接就宕机了。
此时，明显这个订单消息就丢失了啊，因为RabbitMQ那里已经没有了。。。
这会导致什么样的尴尬体验呢？就是一个用户支付了8999元，对一个iphone8下了订单，结果呢，死等活等了好几天，就是不见网站上显示他的iphone8在发货。
搞了半天，原因就是他的那个iphone8的订单在仓储服务那里，还没来得及调度发货直接就宕机了，导致这个订单消息就一直丢失了，
始终没有给这个用户通知仓库系统进行发货。
这个问题，是不是很尴尬？所以说，技术问题是会严重影响企业的核心业务流程的！
还记得上面的仓储服务消费消息的代码中，有一行关键的代码：
<div align="center"> <img src="../../pics/mq问答10.png"/> </div><br>

这行代码对channel.basicConsume()方法，传入的第二个参数：true，其实就是一个关键的参数。
这个true就代表了一个核心的含义，他的意思是，RabbitMQ只要把一个消息投递到仓储服务手上，立马就标记这个消息删除了。
但是在这个默认的配置之下，要是仓储服务收到一个订单消息，结果还没来得及完成耗时几十秒的仓储调度发货的业务逻辑，结果突然宕机了，
那么这个订单消息就永久性丢失了！

所以这个时候，我们如果希望不要因为仓储服务的突然宕机导致一条订单消息丢失，就需要改造一下仓储服务消费消息的代码了。
首先，我们需要把那个参数从true改为false，如下代码所示：
<div align="center"> <img src="../../pics/mq问答11.png"/> </div><br>

只要修改为false之后，RabbitMQ就不会盲目的投递消息到仓储服务，立马就删除消息了，说白了就是关闭autoAck的行为，
不要自作主张的认为消息处理成功了。
接着，我们需要改造一下处理订单消息的代码，如下代码所示。
<div align="center"> <img src="../../pics/mq问答12.png"/> </div><br>

这段代码，说白了，就是在对订单完成了调度发货之后，在finally代码块中手动执行了ack操作，
说我自己已经完成了耗时几十秒的业务逻辑的处理，现在可以手动ack通知RabbitMQ，这个消息处理完毕了。
[出现异常？？？]

此时整个架构运行流程大致看起来跟下面的图那样子。
<div align="center"> <img src="../../pics/mq问答13.png"/> </div><br>

架构流程改成上面那样后，就意味着只有完成了仓储调度发货的代码业务逻辑，确保仓库系统收到通知之后，
仓储服务才会在代码中手动发送ack消息给RabbitMQ。
此时，RabbitMQ收到了这个ack消息，才会标记对应的订单消息被删除了。
如果说在仓储服务收到了订单消息，但是还没来得及完成仓储调度发货的业务逻辑，那也就绝对不会执行这条订单消息的ack操作，
然后RabbitMQ也就不会收到这条订单消息的ack通知。
一旦RabbitMQ发现代表消费者的某个仓储服务实例突然宕机了，而这个仓储服务收到的一些订单消息还没来得及处理，没给自己发送那些消息的ack通知。
此时，RabbitMQ会自动对这条订单消息重发推送给其他在运行中的仓储服务实例，让其他的仓储服务实例去处理这条订单消息。
这样的话，就可以保证这条订单消息不会因为某个仓储服务实例的宕机而丢失，他会确保必须由某个仓储服务实例完成这条订单消息的调度发货处理，
然后才会删除那条订单消息。

最后再来一张图，大家直观的感受一下：
<div align="center"> <img src="../../pics/mq问答14.png"/> </div><br>

实际上无论是RocketMQ、Kafka还是RabbitMQ，都有类似的autoAck或者是手动ack的机制。
线上生产环境中运行时，你必须要考虑到消费者服务可能宕机的问题。
如果消费者服务没处理完消息就自己宕机了，那么一定会导致部分消息的丢失，进而影响核心业务流程的运转。
因此大家在线上使用MQ时，一定要充分考虑这些潜在问题，同时结合具体的MQ提供的一些API、参数来进行合理设置，确保消息不要随意丢失。