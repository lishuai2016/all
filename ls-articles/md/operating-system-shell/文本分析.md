---
title: 文本分析
categories: 
- shell
tags:
---

Linux命令


cat word.txt 
 had to keep breathing,even though there was no reason to hope. 
 我要继续呼吸，因为明天太阳将会升起， 
 I gotta keep breathing,because tomorrow ，the sun will rise. 
 谁知道潮水会带来什么？ 
 Who knows what the tide could bring?


一、Linux命令类
1、tail
最常用的tail -f
tail -300f shopbase.log #倒数300行并进入实时监听文件写入模式

2、grep

grep [-acinv] [--color=auto] '搜寻字符串' filename
选项与参数：
-a ：将 binary 文件以 text 文件的方式搜寻数据
-c ：计算找到 '搜寻字符串' 的次数
-i ：忽略大小写的不同，所以大小写视为相同
-n ：顺便输出行号
-v ：反向选择，亦即显示出没有 '搜寻字符串' 内容的那一行！
--color=auto ：可以将找到的关键词部分加上颜色的显示喔！

备注：使用方式，简单来说就是查找什么，在哪里查找，查找的模式
grep forest f.txt     #文件查找
grep forest f.txt cpf.txt #多文件查找
grep 'log' /home/admin -r -n #目录下查找所有符合关键字的文件（格式是：文件名在前，包含查找关键字的内容在后）
cat f.txt | grep -i shopbase    
grep 'shopbase' /home/admin -r -n --include *.{vm,java} #指定文件后缀
grep 'shopbase' /home/admin -r -n --exclude *.{vm,java} #反匹配
seq 10 | grep 5 -A 3    #上匹配
输出
5
6
7
8

seq 10 | grep 5 -B 3    #下匹配
输出
2
3
4
5

seq 10 | grep 5 -C 3    #上下匹配，平时用这个就妥了
输出
2
3
4
5
6
7
8

cat f.txt | grep -c 'SHOPBASE'


3、awk（分析文件中的内容，可以在指定的目录下的文件中查找内容）
整理：
NR 记录数 NR可以理解为Number of Record的缩写
NF 单词数  NF表示目前的记录被分割的字段的数目，NF可以理解为Number of Field。
$0 代表整行数据    $1代表第一个单词，依次类推
-F:  指定一行内单词之间的分隔符为：
{print} 默认打印整行



3.1 基础命令

awk '{print $4,$6}' f.txt   
打印文本中每一行的第四个和第六个单词，可以指定句中单词的分隔符，每一行切分单词的下标从1开始，$0代表整行


awk '{print NR,$0}' f.txt cpf.txt 
NR:NR表示从awk开始执行后，按照记录分隔符读取的数据次数，默认的记录分隔符为换行符，因此默认的就是读取的数据行数，NR可以理解为Number of Record的缩写。
awk '{print NR,$0}' word.txt
输出：
1  had to keep breathing,even though there was no reason to hope. 
2  我要继续呼吸，因为明天太阳将会升起， 
3  I gotta keep breathing,because tomorrow ，the sun will rise. 
4  谁知道潮水会带来什么？ 
5  Who knows what the tide could bring?

awk '{print NR}' word.txt 
1
2
3
4
5

NR其实就是行号


awk '{print FNR,$0}' f.txt cpf.txt
FNR:在awk处理多个输入文件的时候，在处理完第一个文件后，NR并不会从1开始，而是继续累加，因此就出现了FNR，每当处理一个新文件的时候，FNR就从1开始计数，FNR可以理解为File Number of Record。

awk '{print NR,$0}' word.txt word1.txt 
1  had to keep breathing,even though there was no reason to hope. 
2  我要继续呼吸，因为明天太阳将会升起， 
3  I gotta keep breathing,because tomorrow ，the sun will rise. 
4  谁知道潮水会带来什么？ 
5  Who knows what the tide could bring?
6  had to keep breathing,even though there was no reason to hope. 
7  我要继续呼吸，因为明天太阳将会升起， 
8  I gotta keep breathing,because tomorrow ，the sun will rise. 
9  谁知道潮水会带来什么？ 
10  Who knows what the tide could bring?

awk '{print FNR,$0}' word.txt word1.txt 
1  had to keep breathing,even though there was no reason to hope. 
2  我要继续呼吸，因为明天太阳将会升起， 
3  I gotta keep breathing,because tomorrow ，the sun will rise. 
4  谁知道潮水会带来什么？ 
5  Who knows what the tide could bring?
1  had to keep breathing,even though there was no reason to hope. 
2  我要继续呼吸，因为明天太阳将会升起， 
3  I gotta keep breathing,because tomorrow ，the sun will rise. 
4  谁知道潮水会带来什么？ 
5  Who knows what the tide could bring?



awk '{print FNR,FILENAME,$0}' f.txt cpf.txt    FILENAME输出文件的名称
awk '{print FILENAME,"NR="NR,"FNR="FNR,"$"NF"="$NF}' f.txt cpf.txt   打印文件名称 总行数 文件内行数 每一行的最后一个单词
 awk '{print FILENAME,"NR="NR,"FNR="FNR,"$"NF"="$NF}' word.txt word1.txt
word.txt NR=1 FNR=1 $11=hope.
word.txt NR=2 FNR=2 $1=我要继续呼吸，因为明天太阳将会升起，
word.txt NR=3 FNR=3 $9=rise.
word.txt NR=4 FNR=4 $1=谁知道潮水会带来什么？
word.txt NR=5 FNR=5 $7=bring?
word1.txt NR=6 FNR=1 $11=hope.
word1.txt NR=7 FNR=2 $1=我要继续呼吸，因为明天太阳将会升起，
word1.txt NR=8 FNR=3 $9=rise.
word1.txt NR=9 FNR=4 $1=谁知道潮水会带来什么？
word1.txt NR=10 FNR=5 $7=bring?

echo 1:2:3:4 | awk -F: '{print $1,$2,$3,$4}' 


awk '{print}' word.txt 
 had to keep breathing,even though there was no reason to hope. 
 我要继续呼吸，因为明天太阳将会升起， 
 I gotta keep breathing,because tomorrow ，the sun will rise. 
 谁知道潮水会带来什么？ 
 Who knows what the tide could bring?


3.2、 匹配

awk '/ldb/ {print}' f.txt   #匹配ldb
awk '!/ldb/ {print}' f.txt  #不匹配ldb
awk '/ldb/ && /LISTEN/ {print}' f.txt   #匹配ldb和LISTEN
awk '$5 ~ /ldb/ {print}' f.txt #第五列匹配ldb







3.3、find（查找文件）
find /home/admin /tmp /usr -name \*.log(多个目录去找以.log结尾的文件   注意\*.log这个写法去掉\不行)
find . -iname \*.txt(大小写都匹配)    这样会把目录也列出了
find . -type d(当前目录下的所有子目录)
find /usr -type l(当前目录下所有的符号链接)
find /usr -type l -name "z*" -ls(符号链接的详细信息 eg:inode,目录)
find /home/admin -size +250000k(超过250000k的文件，当然+改成-就是小于了)
find /home/admin f -perm 777 -exec ls -l {} \; (按照权限查询文件)
find /home/admin -atime -1  1天内访问过的文件
find /home/admin -ctime -1  1天内状态改变过的文件    
find /home/admin -mtime -1  1天内修改过的文件
find /home/admin -amin -1  1分钟内访问过的文件
find /home/admin -cmin -1  1分钟内状态改变过的文件    
find /home/admin -mmin -1  1分钟内修改过的文件
pgm
批量查询vm-shopbase满足条件的日志

pgm -A -f vm-shopbase 'cat /home/admin/shopbase/logs/shopbase.log.2017-01-17|grep 2069861630'




4、top
top除了看一些基本信息之外，剩下的就是配合来查询vm的各种问题了

ps -ef | grep java
top -H -p pid
获得线程10进制转16进制后jstack去抓看这个线程到底在干啥

其他
netstat -nat|awk  '{print $6}'|sort|uniq -c|sort -rn 
#查看当前连接，注意close_wait偏高的情况，比如如下
screenshot.png








    查找文件
    find / -name filename.txt 根据名称查找/目录下的filename.txt文件。
    find . -name "*.xml" 递归查找所有的xml文件
    find . -name "*" |xargs grep "hello" 递归查找所有文件内容中包含hello world的xml文件
    find ./ -size 0 | xargs rm -f & 删除文件大小为零的文件
    grep -H 'spring' *.xml 查找所以有的包含spring的xml文件
    ls -l | grep '.jar' 查找当前目录中的所有jar文件
    grep 'test' d* 显示所有以d开头的文件中包含test的行。
    grep 'test' aa bb cc 显示在aa，bb，cc文件中匹配test的行。
    grep '[a-z]\{5\}' aa 显示所有包含每个字符串至少有5个连续小写字符的字符串的行。
    查看一个程序是否运行
    
    ps –ef|grep tomcat 查看所有有关tomcat的进程
    
    ps -ef|grep --color java 高亮要查询的关键字
    
    终止进程
    
    kill -9 19979 终止线程号位19979的进程
    
    查看文件，包含隐藏文件
    
    ls -al
    
    当前工作目录
    
    pwd
    
    
    
    cp source dest 复制文件
    
    cp -r sourceFolder targetFolder 递归复制整个文件夹
    
    scp sourecFile name@ip:addr 远程拷贝
    
    创建目录
    
    mkdir newfolder
    
    删除目录
    
    
    rmdir deleteEmptyFolder 删除空目录 
    
    rm -rf deleteFile 递归删除目录中所有内容
    
    移动文件
    
    mv /temp/movefile /targetFolder
    
    重命名
    
    mv oldNameFile newNameFile
    
    切换用户
    
    su -username
    
    修改文件权限
    
    chmod 777 file.java file.java的权限-rwxrwxrwx，r表示读、w表示写、x表示可执行
    
    压缩文件
    
    tar -czf test.tar.gz /test1 /test2
    
    列出压缩文件列表
    
    tar -tzf test.tar.gz
    
    解压文件
    
    tar -xvzf test.tar.gz
    
    查看文件前10行
    
    head -n 10 example.txt
    
    查看文件后10行
    
    tail -n 10 example.txt
    
    查看日志最近更新
    
    tail -f exmaple.log 这个命令会自动显示新增内容，屏幕只显示10行内容的（可设置）。
    
    使用超级管理员身份执行命令
    
    sudo rm a.txt 使用管理员身份删除文件
    
    查看端口占用情况
    
    netstat -tln | grep 8080 查看端口8080的使用情况
    
    查看端口属于哪个进程
    
    lsof -i :8080
    
    查看进程
    
    ps aux|grep java 查看java进程
    
    ps aux 查看所有进程
    
    以树状格式列出目录
    
    tree a
    
    PS：Mac下使用tree命令
    
    文件下载
    
    
    wget http://file.tgz 
    
    PS ：Mac下安装wget命令
    
    curl http://file.tgz
    
    网络检测
    
    ping www.just-ping.com
    
    远程登录
    
    ssh userName@ip
    
    打印信息
    
    echo $JAVA_HOME 打印java home环境变量的值
    
    Java常用命令
    
    java
    
    javac
    
    javap
    
    jps
    
    jstat
    
    jmap
    
    jstack
    
    其他命令
    
    svn 
    
    git 
    
    maven
    
    Linux命令学习网站
    
    http://explainshell.com/
    
    ps -ef | grep mysql
    
    ps aux |grep ads_app | grep hive
    
    ps aux| head -n 3
    
    ps -aux|grep  -i tmux
    
    ps aux|grep -i watch
    
    
    
    
    sort、uniq和rnk
    
    
    sort | uniq -c | sort -rnk 1 在数据统计中的重要用途------按频率排序
    
           我们来看看a.txt文件：
    
    taoge@localhost Desktop> cat a.txt
    123
    456
    1111
    456
    123
    123
    1
    2
    3
    taoge@localhost Desktop> 
           先对其排序（按串排序）：
    taoge@localhost Desktop> cat a.txt | sort
    1
    1111
    123
    123
    123
    2
    3
    456
    456
    taoge@localhost Desktop> 
          再进行聚合：
    taoge@localhost Desktop> cat a.txt | sort | uniq -c
          1 1
          1 1111
          3 123
          1 2
          1 3
          2 456
    taoge@localhost Desktop>  
          聚合后得到频次， 最后对频次进行排序（r表示逆向排序， n表示按数值排序， k表示按第k列进行排序）：
    taoge@localhost Desktop> cat a.txt |sort | uniq -c | sort -rnk 1
          3 123
          2 456
          1 3
          1 2
          1 1111
          1 1
    
    ll /home/ | grep ads_app
    history | grep spark
    ll .bashrc && grep QUEUE .bashrc && grep -A1 queue hadoop_conf/mapred-site.xml
    date && ll .bashrc && grep QUEUE .bashrc && grep -A1 queue hadoop_conf/mapred-site.xml
    date +%s
    PS1='[\u@\h \W]\$ ' && TERM=xterm && export TERM
    export BEE_PASS=NjA0
    clear;echo -e '\033[32mLogin 10.198.47.106 done. Enjoy it.\033[0m'
    scp congyihao@10.12.140.104:D:/IdeaProjects/ads-data-base_data_model/ad_base_model_order_gmv_measure /home/ads_app/congyihao/test/ad_base_model_order_gmv_measure
    rz -E
    quit
    vimdiff new_impr_size_16 old_impr_size_16 
    kill -9 17964
    echo "hello world" > hello.txt
    ls -alh
    nohup sh batch_bushu.sh 2018-05-01 2018-05-17&
    tar xzf mkt_re_ord_track_with_click_id.tgz
    nohup python pv_join_clk.py 2018-06-10 external_repage_clk >pv0610.log &
    bash cp_swc_request.sh 
    echo $?
    history | grep distcp
    tar -xzf tmux-2.7.tar.gz 
    Libevent-release-2.1.8-stable  memcached安装依赖
    fg 1
    fg
    kill % 1
    tmux new-session -s cyh-monitor
    which tmux
    which mail
    cp tmux $HOME/congyihao/local/bin
    ln ./tmux /home/ads_app/bin/tmux
    ./tmux new-session -s cyh-monitor
    ./tmux attach-session -t cyh-monitor
    history -l
    source .iterm2_shell_integration.bash
    chmod +x check_migration.py 
    lzop
    more repairedisk.log 
    env | grep USER | cut -d '{{=}}' -f {{1, 2}}
    unzip py4j-0.10.7.zip 
    watch date
    watch -n 60 date &
    ipconfig -all
    rename
    unzip --help
    tmux attach-session -t cyh-monitor
    free -g
    crontab -e
    nohup bash run_month_2018.sh > run_month_2018.txt 2> run_month_2018.log &
    wc -l ./*
    grep create ./*
    rz -E
    top -5  静默用户相关消耗数据情况.data 
    zip intel_order_detail.txt intel_order_detail.txt
    source cluster_alias.sh
    cat rank_compare_2018-10-22.txt |grep 裤子 > data_f.txt
    Sent -> /Users/pangkuo/Documents/workspace/python/
    Received /Users/pangkuo/Downloads/lingzhi_analysis_check.sh